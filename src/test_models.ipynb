{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdf9b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_set_path = os.path.join(os.path.abspath(''), os.pardir, 'datasets', 'ma_dataset', 'combined', 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1086069c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "BATCH_SIZE = 1\n",
    "NUM_QUERIES = 6\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8ec93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from test_loss import gather_eval_data, show_lines\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174fc846",
   "metadata": {},
   "source": [
    "# MS-ERFNet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4c3eba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mse_dataset import CropRowDataset\n",
    "mse_img_height = 512\n",
    "mse_img_width = 512\n",
    "ds_mse = CropRowDataset(os.path.join(test_set_path, 'masks'), os.path.join(test_set_path, 'imgs'), (mse_img_height, mse_img_width), False)\n",
    "dl_mse = DataLoader(ds_mse, BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "from ms_erfnet import MSERFNet\n",
    "p_mse = os.path.join(os.path.abspath(''), 'best_mse.pt')\n",
    "m_mse = MSERFNet()\n",
    "m_mse.load_state_dict(torch.load(p_mse, map_location=DEVICE))\n",
    "m_mse.to(DEVICE)\n",
    "m_mse.eval()\n",
    "\n",
    "import cv2 as cv\n",
    "from mse_croprows_in_masks import MSECropRowFinder\n",
    "crf_mse = MSECropRowFinder()\n",
    "\n",
    "THRESHOLD = 0.2\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "with torch.no_grad():\n",
    "  preds = []\n",
    "  gts = []\n",
    "  for test_batch in tqdm(dl_mse, desc=f'MS-ERFNet'):\n",
    "    imgs = test_batch['image'].to(DEVICE)\n",
    "    gt = [p.tolist()[0] for p in test_batch['poly']]\n",
    "    gts.append(gt)\n",
    "\n",
    "    start_time = time.time()\n",
    "    pred = m_mse(imgs)\n",
    "    for i in range (BATCH_SIZE):\n",
    "      current = pred[i, 0]\n",
    "      norm = (current - current.min()) / (current.max() - current.min() + 1e-8)\n",
    "      np_norm = norm.cpu().numpy()\n",
    "\n",
    "      fixed_bin = (np_norm < THRESHOLD).astype(np.uint8)\n",
    "      fixed_bin = cv.morphologyEx(fixed_bin, cv.MORPH_CLOSE, kernel, iterations=1)\n",
    "      fixed_lines, fixed_pt_lines = crf_mse.process(fixed_bin)\n",
    "      preds.append(fixed_lines)\n",
    "    duration = time.time() - start_time\n",
    "  fps = len(preds) / duration\n",
    "\n",
    "  gather_eval_data(os.path.join(os.path.abspath(''), os.pardir, 'mse_eval_data.csv'), preds, gts, ds_mse.filenames, fps, mse_img_height, mse_img_width)\n",
    "\n",
    "    # plt.imshow(pred[i, 0].cpu().numpy(), cmap='jet')\n",
    "    # plt.colorbar()\n",
    "    # plt.show()\n",
    "\n",
    "    # np_8 = (np_norm * 255).astype(np.uint8)\n",
    "    # _, otsu = cv.threshold(np_8, 0, 1, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "    # otsu = cv.morphologyEx(otsu,cv.MORPH_OPEN, kernel, iterations=1)\n",
    "    \n",
    "    # fig, axs = plt.subplots(1, 3, figsize=(15, 4))\n",
    "    \n",
    "    # axs[0].imshow(np_norm, cmap='jet')\n",
    "    # axs[0].set_title('Heatmap normalisiert')\n",
    "    # axs[0].axis('off')\n",
    "\n",
    "    # axs[1].imshow(otsu, cmap='gray')\n",
    "    # axs[1].set_title('Otsu')\n",
    "    # axs[1].axis('off')\n",
    "\n",
    "    # axs[2].imshow(fixed_bin, cmap='gray')\n",
    "    # axs[2].set_title('Fixed Thresh')\n",
    "    # axs[2].axis('off')\n",
    "\n",
    "    # plt.tight_layout()\n",
    "    # plt.show()\n",
    "\n",
    "    # line_img = show_lines(imgs[i], fixed_lines, gt)\n",
    "    # plt.imshow(line_img)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n",
    "\n",
    "      \n",
    "    # line_pairings = match_lines(fixed_lines, gt_lines, np_norm.shape[0], np_norm.shape[1])\n",
    "\n",
    "    # print(f'Section-Angle-Loss: {section_angle_loss(line_pairings, np_norm.shape[0], np_norm.shape[1])}')\n",
    "    # print(f'Lateral-Pixel-Loss: {lateral_pixel_loss(line_pairings, np_norm.shape[0], np_norm.shape[1])}')\n",
    "    # print(f'Found {len(fixed_lines) - len(gt_lines)} lines more than in Groundtruth')\n",
    "    # pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b4e7e4",
   "metadata": {},
   "source": [
    "# InstaCropNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dce18b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from SegCropNet.dataloader.data_loaders import TusimpleSet\n",
    "ds_insta = TusimpleSet(test_set_path, img_size=(256, 512), transform=False, shuffle=False)\n",
    "dl_insta = DataLoader(ds_insta, BATCH_SIZE, shuffle=False, num_workers=0, collate_fn=lambda x: x)\n",
    "\n",
    "from SegCropNet.model.SegCropNet.SegCropNet import SegCropNet\n",
    "p_insta = os.path.join(os.path.abspath(''), 'best_insta.pt')\n",
    "m_insta = SegCropNet(arch='UNet')\n",
    "m_insta.load_state_dict(torch.load(p_insta, map_location=DEVICE))\n",
    "m_insta.to(DEVICE)\n",
    "m_insta.eval()\n",
    "\n",
    "from insta_cluster import dbscan\n",
    "import numpy as np\n",
    "from mse_croprows_in_masks import MSECropRowFinder\n",
    "crf_insta = MSECropRowFinder()\n",
    "\n",
    "THRESHOLD = 0.2\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "with torch.no_grad():\n",
    "  preds = []\n",
    "  gts = []\n",
    "  duration = 0.0\n",
    "  for test_batch in tqdm(dl_insta, desc=f'InstaCropNet'):\n",
    "    inputs = test_batch[0]['input'].type(torch.FloatTensor).to(DEVICE)\n",
    "    binaries = test_batch[0]['binary'].type(torch.LongTensor).to(DEVICE)\n",
    "    instances = test_batch[0]['instance'].type(torch.FloatTensor).to(DEVICE)\n",
    "    gt = test_batch[0]['poly']\n",
    "    gts.append(test_batch[0]['poly'])\n",
    "\n",
    "    start_time = time.time()\n",
    "    pred = m_insta(inputs.unsqueeze(0))\n",
    "    for i in range (BATCH_SIZE):\n",
    "      pred_lines = dbscan((pred['binary_seg_pred'][i, 0].cpu().numpy() * 255).astype(np.uint8), pred['instance_seg_logits'][i].permute(1,2,0).cpu().numpy())\n",
    "      preds.append(pred_lines)\n",
    "    duration += time.time() - start_time\n",
    "  fps = len(preds) / duration\n",
    "\n",
    "  gather_eval_data(os.path.join(os.path.abspath(''), os.pardir, 'insta_eval_data.csv'), preds, gts, ds_insta._gt_img_list, fps, ds_insta.img_size[0], ds_insta.img_size[1])\n",
    "\n",
    "      # fig, axs = plt.subplots(2, 3, figsize=(15, 4))\n",
    "      \n",
    "      # inp = inputs.cpu() * 0.5 + 0.5\n",
    "      # inp = show_lines(inp, pred_lines, gt)\n",
    "      # axs[0,0].imshow(inp)\n",
    "      # axs[0,0].set_title('Input')\n",
    "      # axs[0,0].axis('off')\n",
    "\n",
    "      # axs[0,1].imshow(binaries.cpu(), cmap='gray')\n",
    "      # axs[0,1].set_title('GT Binary')\n",
    "      # axs[0,1].axis('off')\n",
    "\n",
    "      # axs[0,2].imshow(instances.cpu(), cmap='gray')\n",
    "      # axs[0,2].set_title('GT Instanced Binary')\n",
    "      # axs[0,2].axis('off')\n",
    "      \n",
    "      # axs[1,0].imshow(F.softmax(pred['binary_seg_logits'][i, 1], dim=0).cpu().numpy(), cmap='jet')\n",
    "      # axs[1,0].set_title('Probability of Crop Row')\n",
    "      # axs[1,0].axis('off')\n",
    "\n",
    "      # axs[1,1].imshow(pred['binary_seg_pred'][i, 0].cpu().numpy(), cmap='gray')\n",
    "      # axs[1,1].set_title('Binary')\n",
    "      # axs[1,1].axis('off')\n",
    "\n",
    "      # axs[1,2].imshow(pred['instance_seg_logits'][i].permute(1,2,0).cpu().numpy(), cmap='gray')\n",
    "      # axs[1,2].set_title('Instanced Binary')\n",
    "      # axs[1,2].axis('off')\n",
    "\n",
    "      # plt.tight_layout()\n",
    "      # plt.show()\n",
    "      # pass\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61528939",
   "metadata": {},
   "source": [
    "# Transformer Based Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a6054e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer_dataset import MaskLessDataset\n",
    "ds_transformer = MaskLessDataset(os.path.join(test_set_path, 'labels'), os.path.join(test_set_path, 'imgs'), NUM_QUERIES, (360, 640), full_transform=False)\n",
    "dl_transformer = DataLoader(ds_transformer, BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "from transformer import TransformerBasedModel\n",
    "p_transformer = os.path.join(os.path.abspath(''), 'best_transformer.pt')\n",
    "m_transformer = TransformerBasedModel(max_crop_rows=NUM_QUERIES)\n",
    "m_transformer.load_state_dict(torch.load(p_transformer, map_location=DEVICE))\n",
    "m_transformer.to(DEVICE)\n",
    "m_transformer.eval()\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "with torch.no_grad():\n",
    "  preds = []\n",
    "  gts = []\n",
    "  for test_batch in tqdm(dl_transformer, desc=f'Transformer'):\n",
    "    imgs = test_batch['image'].to(DEVICE)\n",
    "    gt = test_batch['gt']\n",
    "    gt_classes = test_batch['class']\n",
    "    gts.append(gt.squeeze().cpu().tolist())\n",
    "\n",
    "    start_time = time.time()\n",
    "    probs, pred = m_transformer(imgs)\n",
    "    np_probs = probs.squeeze().cpu().numpy()\n",
    "    confident = np.where(np_probs[:,1] > 0.8)\n",
    "    preds.append(pred.squeeze().cpu().numpy()[confident].tolist())\n",
    "    duration = time.time() - start_time\n",
    "  fps = len(preds) / duration\n",
    "\n",
    "  gather_eval_data(os.path.join(os.path.abspath(''), os.pardir, 'trans_eval_data.csv'), preds, gts, ds_transformer.filenames, fps, 360, 640)\n",
    "\n",
    "    # line_img = show_lines(imgs[0], pred.squeeze().cpu().numpy()[confident].tolist(), gt.squeeze().cpu().tolist())\n",
    "    # plt.imshow(line_img)\n",
    "    # plt.axis('off')\n",
    "    # plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
