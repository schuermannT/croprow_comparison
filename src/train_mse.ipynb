{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67a5eb4-36a6-484e-92f3-63712b5bc8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a938195a-448a-44b5-be94-6d580db53938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging\n",
    "import logging\n",
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(filename='mse.log', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cb681-5d05-45c4-bb15-60e3c27be0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters - according to paper\n",
    "NUM_EPOCHS = 1000\n",
    "BATCH_SIZE = 2#16\n",
    "LEARNING_RATE = 0.007\n",
    "IMG_SIZE = (512, 512)\n",
    "NUM_QUERIES = 11\n",
    "NUM_WORKERS =  0#16\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)\n",
    "logger.info(f'Device: {DEVICE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d557ae8e-cecc-4dc2-a249-e2c915b63998",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init: Datasets and Dataloader\n",
    "import os\n",
    "from mse_dataset import CropRowDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#train_path = os.path.join(os.path.abspath(''), 'dataset', 'train')\n",
    "train_path = os.path.join(os.path.abspath(''), os.pardir, 'datasets', 'ma_dataset', 'combined', 'train')\n",
    "train_dataset = CropRowDataset(label_path = os.path.join(train_path, 'masks'), img_path = os.path.join(train_path, 'imgs'), img_size=IMG_SIZE)\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers = NUM_WORKERS)\n",
    "\n",
    "#val_path = os.path.join(os.path.abspath(''), 'dataset', 'val')\n",
    "val_path = os.path.join(os.path.abspath(''), os.pardir, 'datasets', 'ma_dataset', 'combined', 'val')\n",
    "val_dataset = CropRowDataset(label_path = os.path.join(val_path, 'masks'), img_path = os.path.join(val_path, 'imgs'), img_size=IMG_SIZE)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "logger.info('created datasets and dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10f8ff6-f661-477a-a2db-42fe58c5df87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init: Model\n",
    "import torch.optim as optim\n",
    "from ms_erfnet import MSERFNet\n",
    "from hungarian_loss import HungarianLoss\n",
    "model = MSERFNet().to(DEVICE)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-5)\n",
    "patience_counter = 0\n",
    "best_loss = float('inf')\n",
    "patience_limit = 20\n",
    "epoch_start = 0\n",
    "logger.info('created model and optimizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eff8e0-7b2c-49cc-b4f7-6716c5673da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model if already existing\n",
    "checkpoint_path = os.path.join(os.path.abspath(''), 'mse_checkpoint.pt.tar')\n",
    "if os.path.isfile(checkpoint_path):\n",
    "    logger.info('found existing model')\n",
    "    checkpoint = torch.load(checkpoint_path, map_location=DEVICE)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    epoch_start = checkpoint['epoch']\n",
    "    best_loss = checkpoint['loss']\n",
    "    patience_counter = checkpoint['patience_counter']\n",
    "    logger.info('loaded existing model for continuation of training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f38f86b-407e-4546-98c2-4e2a0fdd0459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Cycle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "for epoch in range(epoch_start, NUM_EPOCHS, 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for train_batch in tqdm(train_loader, desc=f'Epoch {epoch+1}/{NUM_EPOCHS}'):\n",
    "        train_images = train_batch['image'].to(DEVICE)\n",
    "        train_gt_params = train_batch['gt'].to(DEVICE)\n",
    "        \n",
    "        #===DEBUG===\n",
    "        # show_mask = train_gt_params[0].squeeze(0).cpu().numpy()\n",
    "        # show_img = train_images[0].cpu().permute(1,2,0).numpy()\n",
    "        # fig, axs = plt.subplots(1, 2)\n",
    "        # axs[0].imshow(show_img)\n",
    "        # axs[0].axis('off')\n",
    "        # axs[1].imshow(show_mask, cmap='gray', vmin=0, vmax=1)\n",
    "        # axs[1].axis('off')\n",
    "        # plt.tight_layout()\n",
    "        # plt.show()\n",
    "        #===DEBUG END===\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        train_pred_params = model(train_images)\n",
    "        train_gt_params = train_gt_params.squeeze(1).long()\n",
    "        batch_loss = torch.nn.functional.cross_entropy(train_pred_params, train_gt_params, reduction='mean')\n",
    "\n",
    "        batch_loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += batch_loss.item()\n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for val_batch in tqdm(val_loader, desc='Validation'):\n",
    "            val_imgs = val_batch['image'].to(DEVICE)\n",
    "            val_gt_params = val_batch['gt'].to(DEVICE)\n",
    "            val_pred_params = model(val_imgs)\n",
    "            val_gt_params = val_gt_params.squeeze(1).long()\n",
    "            val_loss += torch.nn.functional.cross_entropy(val_pred_params, val_gt_params, reduction='mean')\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        print(f'train_loss: {avg_train_loss} | val_loss: {avg_val_loss}')\n",
    "        if avg_val_loss < best_loss:\n",
    "            best_loss = avg_val_loss\n",
    "            torch.save(model.state_dict(), 'best_mse.pt')\n",
    "            print('New Model saved')\n",
    "            patience_counter = 0\n",
    "            logger.info(f'updated best_model in epoch {epoch+1} with training_loss: {avg_train_loss} and validation_loss: {avg_val_loss}')\n",
    "        #else:\n",
    "            #patience_counter += 1\n",
    "            #if patience_counter >= patience_limit:\n",
    "                #print('Should: Early stop due to no improvement in validation')\n",
    "                #logger.info(f'Should: Early stopping in epoch {epoch}')\n",
    "                #break\n",
    "    \n",
    "    if (epoch+1) % 10 == 0:\n",
    "        torch.save({'epoch': epoch,\n",
    "                    'model_state_dict': model.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'loss': best_loss,\n",
    "                    'patience_counter': patience_counter},\n",
    "                   'mse_checkpoint.pt.tar')\n",
    "        logger.info(f'created checkpoint for epoch {epoch+1} with training_loss: {avg_train_loss} and validation_loss: {avg_val_loss}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
